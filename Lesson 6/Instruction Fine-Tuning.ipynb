{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOTtGU+Rceo/YCBI72f0/40"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b464248710c34d438732f5214e7a02ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d407997b7fa04bbdb7b72ff501768776","IPY_MODEL_c41ad8fefe254be984571f2404937673","IPY_MODEL_4657fdae640b4d1f857d94792b71fc4a"],"layout":"IPY_MODEL_15275c69615842de86436f5626d99ef2"}},"d407997b7fa04bbdb7b72ff501768776":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6db13451652f47a1992ed638050472ea","placeholder":"​","style":"IPY_MODEL_15ee161b2d9148efb39208a47be1320d","value":"Map: 100%"}},"c41ad8fefe254be984571f2404937673":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_015178827a004c789ef3bfba597c90c2","max":16,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4fcb55d1cc0445d90943d321843fe1b","value":16}},"4657fdae640b4d1f857d94792b71fc4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f3a15a7cb76492bb55999f2eab42fc2","placeholder":"​","style":"IPY_MODEL_845af4316b6c4e928afc2dcf15d8149a","value":" 16/16 [00:00&lt;00:00, 326.85 examples/s]"}},"15275c69615842de86436f5626d99ef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6db13451652f47a1992ed638050472ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ee161b2d9148efb39208a47be1320d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"015178827a004c789ef3bfba597c90c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4fcb55d1cc0445d90943d321843fe1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f3a15a7cb76492bb55999f2eab42fc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"845af4316b6c4e928afc2dcf15d8149a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install peft\n","!pip install torch\n","!pip install datasets\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToH4fVrGJuKE","executionInfo":{"status":"ok","timestamp":1735943781264,"user_tz":480,"elapsed":22456,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"86cdfbed-f0bc-4907-834b-12d0832b6c1b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["Import the necessary libraries"],"metadata":{"id":"FxiFjSal425n"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n","from peft import LoraConfig, get_peft_model\n","from datasets import Dataset, DatasetDict\n","\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""],"metadata":{"id":"421LmCHGJzXH","executionInfo":{"status":"ok","timestamp":1735943813572,"user_tz":480,"elapsed":22892,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Log into Hugging Face with a secure token"],"metadata":{"id":"kghOjs544Y-d"}},{"cell_type":"code","source":["from google.colab import userdata\n","from huggingface_hub import login\n","\n","# Retrieve the Hugging Face token securely\n","hf_token = userdata.get(\"HF_TOKEN\")  # Replace 'HF_TOKEN' with your secret name\n","\n","if not hf_token:\n","    raise ValueError(\"Hugging Face token not found in Colab secrets.\")\n","\n","# Log in using the token\n","login(token=hf_token)\n","print(\"Successfully logged into Hugging Face!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AwwtQ8yfWd1","executionInfo":{"status":"ok","timestamp":1735943842159,"user_tz":480,"elapsed":879,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"687812b6-2dd0-48a2-891c-f8de961f6901"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully logged into Hugging Face!\n"]}]},{"cell_type":"markdown","source":["Create Some Instruction Training Examples to Fine-Tune the Model"],"metadata":{"id":"nbDi4Mkx4dpl"}},{"cell_type":"code","source":["examples = []"],"metadata":{"id":"GLiVbMlP5YQQ","executionInfo":{"status":"ok","timestamp":1735943214190,"user_tz":480,"elapsed":183,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["examples = [\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I haven't received my order #12345 yet. It's been a week.\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: Delayed\n","Reference: #12345\n","Action Taken: Order status check initiated\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I received the wrong item in my order #67890.\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: Wrong Item Delivered\n","Reference: #67890\n","Action Taken: Replacement item initiated\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"My order #98765 is damaged. What should I do?\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: Damaged Item\n","Reference: #98765\n","Action Taken: Return and replacement process initiated\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I want to cancel my order #54321.\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: Cancellation Request\n","Reference: #54321\n","Action Taken: Cancellation process initiated\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I was charged twice for my order #11223. Please help.\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: Billing Issue\n","Reference: #11223\n","Action Taken: Refund request initiated\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"When will my order #44556 arrive?\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: In Transit\n","Reference: #44556\n","Action Taken: Estimated delivery date provided\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"My order #99988 was returned. When will I get my refund?\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: Returned\n","Reference: #99988\n","Action Taken: Refund process initiated\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I can't track my order #66777. Can you help?\",\n","        \"output\": \"\"\"Thank you for contacting TechCorp Support.\n","\n","Order Status: Tracking Issue\n","Reference: #66777\n","Action Taken: Tracking link resent\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\"\"\"\n","    },\n","        {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"My order #56789 was supposed to arrive yesterday, but I haven't received it.\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: Delayed\n","Reference: #56789\n","Action Taken: Initiated a follow-up with the shipping carrier\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I received a damaged item in my order #98765. What should I do?\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: Damaged Item\n","Reference: #98765\n","Action Taken: Replacement process initiated. Return instructions sent.\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I was charged twice for my order #11223. Please help.\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: Billing Issue\n","Reference: #11223\n","Action Taken: Refund process initiated for duplicate charge\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"When will my order #33445 arrive?\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: In Transit\n","Reference: #33445\n","Action Taken: Estimated delivery date provided via email\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I need to cancel my order #44556 immediately.\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: Cancellation Requested\n","Reference: #44556\n","Action Taken: Cancellation process initiated. Confirmation email sent.\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I can't track my order #77889. The tracking link doesn't work.\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: Tracking Issue\n","Reference: #77889\n","Action Taken: Sent updated tracking link. Contacted carrier for more information.\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"I returned my order #99000 last week. When will I get my refund?\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: Returned\n","Reference: #99000\n","Action Taken: Refund process initiated. Refund expected within 5 business days.\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    },\n","    {\n","        \"instruction\": \"Respond to this customer inquiry following our format\",\n","        \"input\": \"My order #11122 arrived, but it's missing some items.\",\n","        \"output\": \"\"\"Thank you for contacting Tech Support.\n","\n","Order Status: Incomplete Order\n","Reference: #11122\n","Action Taken: Missing items identified and replacement initiated\n","\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","Tech Support\"\"\"\n","    }\n","]\n"],"metadata":{"id":"v1ymYyhJb5b-","executionInfo":{"status":"ok","timestamp":1735944821776,"user_tz":480,"elapsed":257,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["Format our training examples the way we want (Instruction, Input, Response)"],"metadata":{"id":"09h5cRYF4pyU"}},{"cell_type":"code","source":["dataset = Dataset.from_list(examples)"],"metadata":{"id":"CcjUo7zkJXDx","executionInfo":{"status":"ok","timestamp":1735944826020,"user_tz":480,"elapsed":159,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["def format_example(example):\n","    instruction = example[\"instruction\"]\n","    input_text = example[\"input\"]\n","    output = example[\"output\"]\n","    return {\n","        \"text\": f\"### Instruction: {instruction}\\n### Input: {input_text}\\n### Response: {output}\"\n","    }\n","\n","formatted_examples = [format_example(ex) for ex in examples]\n","dataset = Dataset.from_list(formatted_examples)"],"metadata":{"id":"cYMCl1X1dEe_","executionInfo":{"status":"ok","timestamp":1735944827040,"user_tz":480,"elapsed":154,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["Load the tokenizer"],"metadata":{"id":"gZlmJvpx4k-c"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","model_name = \"meta-llama/Llama-3.2-1B-Instruct\"  # Adjust to an available model\n","model = AutoModelForCausalLM.from_pretrained(model_name, token=os.getenv(\"HF_TOKEN\"))\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, token=os.getenv(\"HF_TOKEN\"))\n","\n","print(\"Tokenizer loaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5wHLkL1tkEar","executionInfo":{"status":"ok","timestamp":1735944833411,"user_tz":480,"elapsed":3755,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"0d9c4a5d-25a6-496c-cf8c-8e8748a2e48a"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer loaded successfully!\n"]}]},{"cell_type":"code","source":["# Ensure tokenizer has a padding token\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token  # Use eos_token if available\n","    # Or add a new pad token:\n","    # tokenizer.add_special_tokens({'pad_token': '[PAD]'})"],"metadata":{"id":"KjvWAUwxJbG8","executionInfo":{"status":"ok","timestamp":1735944833412,"user_tz":480,"elapsed":2,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["def tokenize_function(examples):\n","    # The dataset now only contains the 'text' column\n","    tokenized = tokenizer(\n","        examples['text'], # Access the 'text' column directly\n","        truncation=True,\n","        padding=\"max_length\",\n","        max_length=512,\n","        return_tensors=\"pt\"\n","    )\n","    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n","    return tokenized\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","\n","\n","# Inspect the tokenized dataset\n","print(tokenized_dataset.column_names)  # Should include 'input_ids' and 'attention_mask'\n","print(tokenized_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["b464248710c34d438732f5214e7a02ed","d407997b7fa04bbdb7b72ff501768776","c41ad8fefe254be984571f2404937673","4657fdae640b4d1f857d94792b71fc4a","15275c69615842de86436f5626d99ef2","6db13451652f47a1992ed638050472ea","15ee161b2d9148efb39208a47be1320d","015178827a004c789ef3bfba597c90c2","c4fcb55d1cc0445d90943d321843fe1b","3f3a15a7cb76492bb55999f2eab42fc2","845af4316b6c4e928afc2dcf15d8149a"]},"id":"eXaj79V9i0XC","executionInfo":{"status":"ok","timestamp":1735944835739,"user_tz":480,"elapsed":149,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"c22a04de-a8c9-4d53-f19a-1e63d675826c"},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/16 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b464248710c34d438732f5214e7a02ed"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['text', 'input_ids', 'attention_mask', 'labels']\n","Dataset({\n","    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 16\n","})\n"]}]},{"cell_type":"code","source":["# LoRA configuration\n","lora_config = LoraConfig(\n","    r=16,  # Rank of the low-rank adaptation matrix. Lower values reduce memory usage.\n","    lora_alpha=32,  # Scaling factor for LoRA updates. Higher values increase capacity.\n","    target_modules=[\"q_proj\", \"v_proj\"],  # Ensure these modules exist in your model.\n","    lora_dropout=0.1,  # Dropout rate to prevent overfitting.\n","    bias=\"none\",  # Do not adapt biases in the model.\n","    task_type=\"CAUSAL_LM\"  # Task type: causal language modeling.\n",")\n","\n","model = get_peft_model(model, lora_config)"],"metadata":{"id":"ksc1ceZ-eUZ-","executionInfo":{"status":"ok","timestamp":1735944837907,"user_tz":480,"elapsed":224,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"./results\",  # Directory where model checkpoints and logs will be saved\n","    num_train_epochs=30,  # Number of complete passes through the training dataset\n","    learning_rate=1e-4,  # Initial learning rate for the optimizer\n","    per_device_train_batch_size=4,  # Batch size per GPU/CPU during training\n","    per_device_eval_batch_size=4,  # Batch size per GPU/CPU during evaluation\n","    warmup_steps=50,  # Number of steps for the learning rate warmup phase\n","    weight_decay=0.01,  # Strength of weight decay for regularization\n","    logging_steps=30,  # Log training metrics every 10 steps\n","    eval_strategy=\"steps\",  # Evaluation strategy: perform evaluation every `eval_steps`\n","    eval_steps=20,  # Perform evaluation every 20 steps\n","    save_strategy=\"steps\",  # Save model checkpoints every `save_steps`\n","    save_steps=20,  # Save model checkpoint every 20 steps\n","    load_best_model_at_end=True,  # Automatically load the best model at the end of training\n","    metric_for_best_model=\"loss\",  # Metric to determine the best model (in this case, lowest loss)\n","    report_to=\"none\"  # Disable integration with external logging tools like W&B\n",")"],"metadata":{"id":"d7ZhtdcXdtEB","executionInfo":{"status":"ok","timestamp":1735944839356,"user_tz":480,"elapsed":161,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into train (80%) and validation (20%)\n","split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n","\n","# Convert to DatasetDict format\n","tokenized_dataset = DatasetDict({\n","    \"train\": split_dataset[\"train\"],\n","    \"validation\": split_dataset[\"test\"],\n","})\n","\n","# Verify the structure\n","print(tokenized_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XgiPs5VlEeO0","executionInfo":{"status":"ok","timestamp":1735944843072,"user_tz":480,"elapsed":236,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"161ae856-6a35-4362-9847-4df6837c4355"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 12\n","    })\n","    validation: Dataset({\n","        features: ['text', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 4\n","    })\n","})\n"]}]},{"cell_type":"code","source":["model.print_trainable_parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjQXyOGY-d0X","executionInfo":{"status":"ok","timestamp":1735944846471,"user_tz":480,"elapsed":155,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"2d5a42ec-8c86-46c5-9be8-f7b0d9a10720"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 1,703,936 || all params: 1,237,518,336 || trainable%: 0.1377\n"]}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],      # Training dataset\n","    eval_dataset=tokenized_dataset[\"validation\"], # Validation dataset\n","    processing_class=tokenizer,                           # Tokenizer\n",")"],"metadata":{"id":"Z4C-B30RAnvK","executionInfo":{"status":"ok","timestamp":1735944852314,"user_tz":480,"elapsed":1569,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# Step 3: Train the model\n","trainer.train()\n","\n","# Save the final model\n","trainer.save_model(\"./final_model\")\n","print(\"Training complete and model saved!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"6pvrJZpmBibE","executionInfo":{"status":"ok","timestamp":1735945140126,"user_tz":480,"elapsed":286589,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"7c9cd954-b870-4981-ab8b-19dca3e71e26"},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [90/90 04:42, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>20</td>\n","      <td>No log</td>\n","      <td>3.390074</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>4.433400</td>\n","      <td>0.468085</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.392600</td>\n","      <td>0.187010</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.392600</td>\n","      <td>0.124155</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete and model saved!\n"]}]},{"cell_type":"markdown","source":["Inference function"],"metadata":{"id":"BCV93pCl8qzO"}},{"cell_type":"code","source":["def generate_response(model, tokenizer, instruction, input_text=\"\"):\n","    \"\"\"\n","    Generate a response using the fine-tuned model.\n","\n","    Args:\n","        model: The fine-tuned model\n","        tokenizer: The tokenizer\n","        instruction: The instruction for the model\n","        input_text: Optional input text\n","\n","    Returns:\n","        str: The generated response\n","    \"\"\"\n","    # Format input to match training format\n","    prompt = f\"### Instruction: {instruction}\\n### Input: {input_text}\\n### Response:\"\n","\n","    # Tokenize the prompt\n","    inputs = tokenizer(prompt,\n","                      return_tensors=\"pt\",\n","                      truncation=True,\n","                      max_length=512,\n","                      add_special_tokens=True)\n","\n","    # Move inputs to the same device as model\n","    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    # Generate response\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens=100,  # Adjust based on desired response length\n","        num_return_sequences=1,\n","        temperature=0.1,     # Adjust for response creativity (0.0-1.0)\n","        do_sample=True,\n","        top_p=0.95,         # Nucleus sampling\n","        top_k=50,           # Top-k sampling\n","        pad_token_id=tokenizer.pad_token_id,\n","        eos_token_id=tokenizer.eos_token_id,\n","    )\n","\n","    # Decode the response\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","    # Extract only the response part (after \"### Response:\")\n","    response_parts = response.split(\"### Response:\")\n","    if len(response_parts) > 1:\n","        response = response_parts[1].strip()\n","\n","    return response\n"],"metadata":{"id":"bFcnekAM8osQ","executionInfo":{"status":"ok","timestamp":1735945145740,"user_tz":480,"elapsed":168,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["def post_process_response(response):\n","    \"\"\"\n","    Post-process the model's response to ensure it adheres to the desired format.\n","\n","    Args:\n","        response (str): The raw response from the model.\n","\n","    Returns:\n","        str: The post-processed response with required sections.\n","    \"\"\"\n","    # Define required sections\n","    sections = [\"Order Status\", \"Reference\", \"Action Taken\", \"Need immediate assistance?\"]\n","    processed_response = response.strip()\n","\n","    # Ensure all required sections exist\n","    for section in sections:\n","        if section not in processed_response:\n","            processed_response += f\"\\n{section}: [Details Missing]\"\n","\n","    return processed_response\n","\n"],"metadata":{"id":"7XgtQitMiqbY","executionInfo":{"status":"ok","timestamp":1735945149121,"user_tz":480,"elapsed":167,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# Example input\n","instruction = \"Respond to this customer inquiry following our format\"\n","input_text = \"I haven't received my order #12345 yet. It's been a week.\"\n","\n","# Generate response\n","raw_response = generate_response(model, tokenizer, instruction, input_text)\n","\n","# Post-process the response\n","final_response = post_process_response(raw_response)\n","\n","# Print the results\n","print(\"\\nINSTRUCTION:\")\n","print(instruction)\n","print(\"\\nINPUT:\")\n","print(input_text)\n","print(\"\\nFINAL RESPONSE:\")\n","print(final_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awKpOrF3LS1F","executionInfo":{"status":"ok","timestamp":1735945152845,"user_tz":480,"elapsed":1747,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"42a3ab76-d341-4880-ac35-e9e159a54129"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INSTRUCTION:\n","Respond to this customer inquiry following our format\n","\n","INPUT:\n","I haven't received my order #12345 yet. It's been a week.\n","\n","FINAL RESPONSE:\n","Thank you for contacting TechCorp Support.\n","\n","Order Status: Delayed\n","Reference: #12345\n","Action Taken: Tracking update sent\n","Need immediate assistance? Call: 1-800-TECH-HELP\n","Your satisfaction is our priority.\n","\n","Best regards,\n","TechCorp Support\n"]}]},{"cell_type":"code","source":["# Check training logs/loss\n","print(\"Training logs from the last few steps:\")\n","print(trainer.state.log_history[-5:])  # Shows the last 5 training logs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fi7TjrxZdRF7","executionInfo":{"status":"ok","timestamp":1735929438626,"user_tz":480,"elapsed":157,"user":{"displayName":"Robert Barton","userId":"08251712997186576593"}},"outputId":"c40f0bd4-702b-4a43-d2be-703e89065f20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training logs from the last few steps:\n","[{'train_runtime': 9.3961, 'train_samples_per_second': 4.257, 'train_steps_per_second': 1.064, 'total_flos': 119789573898240.0, 'train_loss': 2.6833833694458007, 'epoch': 10.0, 'step': 10}]\n"]}]}]}